{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import selenium.webdriver\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_sets=[\"https://www.walmart.com/browse/tv-video/all-tvs/3944_1060825_447913\",\n",
    "    \"https://www.walmart.com/browse/computers/desktop-computers/3944_3951_132982\",\n",
    "         \"https://www.walmart.com/browse/electronics/all-laptop-computers/3944_3951_1089430_132960\",\n",
    "         \"https://www.walmart.com/browse/prepaid-phones/1105910_4527935_1072335\",\n",
    "         \"https://www.walmart.com/browse/electronics/portable-audio/3944_96469\",\n",
    "         \"https://www.walmart.com/browse/electronics/gps-navigation/3944_538883/\",\n",
    "         \"https://www.walmart.com/browse/electronics/sound-bars/3944_77622_8375901_1230415_1107398\",\n",
    "         \"https://www.walmart.com/browse/electronics/digital-slr-cameras/3944_133277_1096663\",\n",
    "         \"https://www.walmart.com/browse/electronics/ipad-tablets/3944_1078524\"]\n",
    "\n",
    "categories=[\"TVs\",\"Desktops\",\"Laptops\",\"Prepaid_phones\",\"Audio\",\"GPS\",\"soundbars\",\"cameras\",\"tablets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: TVs\n",
      "Page number within category: 0\n",
      "Page number within category: 1\n",
      "Page number within category: 2\n",
      "Page number within category: 3\n",
      "Page number within category: 4\n",
      "Page number within category: 5\n",
      "Page number within category: 6\n",
      "Page number within category: 7\n",
      "Page number within category: 8\n",
      "Page number within category: 9\n",
      "Total number of prods: 400\n",
      "0\n",
      "Requesting URL: https://walmart.com/ip/1IBR46ZJFHL5\n",
      "Webpage found ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "20\n",
      "1\n",
      "Requesting URL: https://walmart.com/ip/4655HRO97D87\n",
      "Webpage found ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "19\n",
      "2\n",
      "Requesting URL: https://walmart.com/ip/3MI7DUPI5M39\n",
      "Webpage found ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "24\n",
      "3\n",
      "Requesting URL: https://walmart.com/ip/248GGHX51600\n",
      "Webpage found ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "12\n",
      "4\n",
      "Requesting URL: https://walmart.com/ip/4KZT5E1EK5S9\n"
     ]
    }
   ],
   "source": [
    "for pg in range(len(url_sets)):\n",
    "    # number of pages per category\n",
    "    top_n= [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
    "    url_category=url_sets[pg]\n",
    "    print(\"Category:\",categories[pg])\n",
    "    final_results = []\n",
    "    for i_1 in range(len(top_n)):\n",
    "        print(\"Page number within category:\",i_1)\n",
    "        url_cat=url_category+\"?page=\"+top_n[i_1]\n",
    "        driver= webdriver.Chrome(executable_path='C:/Drivers/chromedriver.exe')\n",
    "        driver.get(url_cat)\n",
    "        body_cat = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "        driver.quit()\n",
    "        soupBody_cat = BeautifulSoup(body_cat)\n",
    "        \n",
    "        \n",
    "        for tmp in soupBody_cat.find_all('div', {'class':'search-result-gridview-item-wrapper'}):\n",
    "\n",
    "            final_results.append(tmp['data-id'])\n",
    "    codelist=final_results\n",
    "    print(\"Total number of prods:\",len(codelist))\n",
    "    # base URL for product page\n",
    "    url1= \"https://walmart.com/ip\"\n",
    "\n",
    "    # Data Headers\n",
    "    WLMTData = [[\"Product_code\",\"Product_name\", \"Product_description\",\"Product_URL\",\n",
    "                 \"Breadcrumb_parent\",\"Breadcrumb_active\",\n",
    "                \"Product_price\", \"Rating_Value\",\"Rating_Count\",\"Recommended_Prods\"]]\n",
    "        \n",
    "    for i in range(len(codelist)):\n",
    "        #creating a list without the place taken in the first loop\n",
    "        print(i)\n",
    "        item_wlmt=codelist[i]\n",
    "        url2=url1+\"/\"+item_wlmt\n",
    "        #print(url2)\n",
    "\n",
    "        try:\n",
    "            driver= webdriver.Chrome(executable_path='C:/Drivers/chromedriver.exe') # Chrome driver is being used.\n",
    "            print (\"Requesting URL: \" + url2)\n",
    "\n",
    "            driver.get(url2)   # URL requested in browser.\n",
    "            print (\"Webpage found ...\")\n",
    "            time.sleep(5)\n",
    "            # Find the document body and get its inner HTML for processing in BeautifulSoup parser.\n",
    "            body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "            print(\"Closing Chrome ...\") # No more usage needed.\n",
    "            driver.quit() \t\t\t\t# Browser Closed.\n",
    "\n",
    "            print(\"Getting data from DOM ...\")\n",
    "            soupBody = BeautifulSoup(body) # Parse the inner HTML using BeautifulSoup\n",
    "            #print(soupBody)\n",
    "\n",
    "            h1ProductName = soupBody.find(\"h1\", {\"class\": \"prod-ProductTitle prod-productTitle-buyBox font-bold\"})\n",
    "            divProductDesc = soupBody.find(\"div\", {\"class\": \"about-desc about-product-description xs-margin-top\"})\n",
    "            liProductBreadcrumb_parent = soupBody.find(\"li\", {\"data-automation-id\": \"breadcrumb-item-0\"})\n",
    "            liProductBreadcrumb_active = soupBody.find(\"li\", {\"class\": \"breadcrumb active\"})\n",
    "            spanProductPrice = soupBody.find(\"span\", {\"class\": \"price-group\"})\n",
    "            spanProductRating = soupBody.find(\"span\", {\"itemprop\": \"ratingValue\"})\n",
    "            spanProductRating_count = soupBody.find(\"span\", {\"class\": \"stars-reviews-count-node\"})\n",
    "            \n",
    "            ################# exceptions #########################\n",
    "            if divProductDesc is None:\n",
    "                divProductDesc=\"Not Available\"\n",
    "            else:\n",
    "                divProductDesc=divProductDesc\n",
    "                \n",
    "            if liProductBreadcrumb_parent is None:\n",
    "                liProductBreadcrumb_parent=\"Not Available\"\n",
    "            else:\n",
    "                liProductBreadcrumb_parent=liProductBreadcrumb_parent\n",
    "                \n",
    "            if liProductBreadcrumb_active is None:\n",
    "                liProductBreadcrumb_active=\"Not Available\"\n",
    "            else:\n",
    "                liProductBreadcrumb_active=liProductBreadcrumb_active\n",
    "                \n",
    "            if spanProductPrice is None:\n",
    "                spanProductPrice=\"NA\"\n",
    "            else:\n",
    "                spanProductPrice=spanProductPrice\n",
    "\n",
    "            if spanProductRating is None or spanProductRating_count is None:\n",
    "                spanProductRating=0.0\n",
    "                spanProductRating_count=\"0 ratings\"\n",
    "            #print(spanProductBreadcrumb_active.text)\n",
    "            else:\n",
    "                spanProductRating=spanProductRating.text\n",
    "                spanProductRating_count=spanProductRating_count.text\n",
    "\n",
    "\n",
    "            ### Recommended Products\n",
    "            reco_prods=[]\n",
    "            for tmp in soupBody.find_all('a', {'class':'tile-link-overlay u-focusTile'}):\n",
    "                reco_prods.append(tmp['data-product-id'])\n",
    "\n",
    "            if len(reco_prods)==0:\n",
    "                reco_prods=[\"Not available\"]\n",
    "            else:\n",
    "                reco_prods=reco_prods\n",
    "            print(len(reco_prods))\n",
    "            WLMTData.append([codelist[i],h1ProductName.text, divProductDesc.text,url2,\n",
    "                             liProductBreadcrumb_parent.text,liProductBreadcrumb_active.text,\n",
    "                            spanProductPrice.text,spanProductRating,spanProductRating_count,reco_prods])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print (str(e))\n",
    "\n",
    "    df=pd.DataFrame(WLMTData)\n",
    "    df.columns = df.iloc[0]\n",
    "    df=df.drop(df.index[0])\n",
    "    print(df.head(2))\n",
    "\n",
    "    # Output File for Products Data. This file will have the data in comma separated form.\n",
    "    df.to_csv('out_'+categories[pg]+'.csv',index=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
