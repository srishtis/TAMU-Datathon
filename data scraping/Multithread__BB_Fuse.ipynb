{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import selenium.webdriver\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Safari\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options  # for suppressing the browser\n",
    "from concurrent.futures import ThreadPoolExecutor, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url1= \"https://walmart.com/ip\"\n",
    "\n",
    "url_sets=[\"https://www.walmart.com/browse/tv-video/all-tvs/3944_1060825_447913\",\n",
    "    \"https://www.walmart.com/browse/computers/desktop-computers/3944_3951_132982\",\n",
    "         \"https://www.walmart.com/browse/electronics/all-laptop-computers/3944_3951_1089430_132960\",\n",
    "         \"https://www.walmart.com/browse/prepaid-phones/1105910_4527935_1072335\",\n",
    "         \"https://www.walmart.com/browse/electronics/portable-audio/3944_96469\",\n",
    "         \"https://www.walmart.com/browse/electronics/gps-navigation/3944_538883/\",\n",
    "         \"https://www.walmart.com/browse/electronics/sound-bars/3944_77622_8375901_1230415_1107398\",\n",
    "         \"https://www.walmart.com/browse/electronics/digital-slr-cameras/3944_133277_1096663\",\n",
    "         \"https://www.walmart.com/browse/electronics/ipad-tablets/3944_1078524\"]\n",
    "\n",
    "categories=[\"TVs\",\"Desktops\",\"Laptops\",\"Prepaid_phones\",\"Audio\",\"GPS\",\"soundbars\",\"cameras\",\"tablets\"]\n",
    "#codelist= [\"7FCB6T54IGW4\",\"4TENT7IJPA5E\",\"38R56ZV9ISK5\",\"6OQGB0M3MO7C\",\"20CTD1EQDDV2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(page_number,url_sets):\n",
    "    for i in range(len(url_sets)):\n",
    "        top_n= [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
    "        url_cat=url_sets[i]+\"?page=\"+top_n[page_number]\n",
    "        option = webdriver.ChromeOptions()\n",
    "        option.add_argument('headless')\n",
    "        driver= webdriver.Chrome(executable_path='C:/chromedriver.exe',options=option)\n",
    "        driver.get(url_cat)\n",
    "        body_cat = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "        driver.quit()\n",
    "        soupBody_cat = BeautifulSoup(body_cat)\n",
    "        for tmp in soupBody_cat.find_all('div', {'class':'search-result-gridview-item-wrapper'}):\n",
    "\n",
    "            final_results.append(tmp['data-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = []\n",
    "final_results = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for number in range(10):\n",
    "        futures.append(\n",
    "            executor.submit(run_process,number)\n",
    "        )\n",
    "wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_n= [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
    "final_results = []\n",
    "for i in range(len(top_n)):\n",
    "    url_cat=\"https://www.walmart.com/browse/electronics/all-laptop-computers/3944_3951_1089430_132960\"+\"?page=\"+top_n[i]\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_argument('headless')\n",
    "    driver= webdriver.Chrome(executable_path='C:/chromedriver.exe',options=option)\n",
    "    driver.get(url_cat)\n",
    "    body_cat = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "    driver.quit()\n",
    "    soupBody_cat = BeautifulSoup(body_cat)\n",
    "    for tmp in soupBody_cat.find_all('div', {'class':'search-result-gridview-item-wrapper'}):\n",
    "\n",
    "        final_results.append(tmp['data-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_results)\n",
    "\n",
    "codelist=final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process2(i,codelist):\n",
    "    #creating a list without the place taken in the first loop\n",
    "    print(i)\n",
    "    item_wlmt=codelist[i]\n",
    "    url2=url1+\"/\"+item_wlmt\n",
    "    #print(url2)\n",
    "    \n",
    "    try:\n",
    "        driver= webdriver.Chrome(executable_path='C:/Drivers/chromedriver.exe') # Chrome driver is being used.\n",
    "        print (\"Requesting URL: \" + url2)\n",
    "\n",
    "        driver.get(url2)   # URL requested in browser.\n",
    "        print (\"Webpage found ...\")\n",
    "        time.sleep(5)\n",
    "        # Find the document body and get its inner HTML for processing in BeautifulSoup parser.\n",
    "        body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "        print(\"Closing Chrome ...\") # No more usage needed.\n",
    "        driver.quit() \t\t\t\t# Browser Closed.\n",
    "\n",
    "        print(\"Getting data from DOM ...\")\n",
    "        soupBody = BeautifulSoup(body) # Parse the inner HTML using BeautifulSoup\n",
    "        #print(soupBody)\n",
    "\n",
    "        h1ProductName = soupBody.find(\"h1\", {\"class\": \"prod-ProductTitle prod-productTitle-buyBox font-bold\"})\n",
    "        divProductDesc = soupBody.find(\"div\", {\"class\": \"about-desc about-product-description xs-margin-top\"})\n",
    "        liProductBreadcrumb_parent = soupBody.find(\"li\", {\"data-automation-id\": \"breadcrumb-item-0\"})\n",
    "        liProductBreadcrumb_active = soupBody.find(\"li\", {\"class\": \"breadcrumb active\"})\n",
    "        spanProductPrice = soupBody.find(\"span\", {\"class\": \"price-group\"})\n",
    "        spanProductRating = soupBody.find(\"span\", {\"itemprop\": \"ratingValue\"})\n",
    "        spanProductRating_count = soupBody.find(\"span\", {\"class\": \"stars-reviews-count-node\"})\n",
    "        \n",
    "        ################# exceptions #########################\n",
    "        if divProductDesc is None:\n",
    "            divProductDesc=\"Not Available\"\n",
    "        else:\n",
    "            divProductDesc=divProductDesc\n",
    "            \n",
    "        if liProductBreadcrumb_parent is None:\n",
    "            liProductBreadcrumb_parent=\"Not Available\"\n",
    "        else:\n",
    "            liProductBreadcrumb_parent=liProductBreadcrumb_parent\n",
    "            \n",
    "        if liProductBreadcrumb_active is None:\n",
    "            liProductBreadcrumb_active=\"Not Available\"\n",
    "        else:\n",
    "            liProductBreadcrumb_active=liProductBreadcrumb_active\n",
    "            \n",
    "        if spanProductPrice is None:\n",
    "            spanProductPrice=\"NA\"\n",
    "        else:\n",
    "            spanProductPrice=spanProductPrice\n",
    "\n",
    "        if spanProductRating is None or spanProductRating_count is None:\n",
    "            spanProductRating=0.0\n",
    "            spanProductRating_count=\"0 ratings\"\n",
    "        #print(spanProductBreadcrumb_active.text)\n",
    "        else:\n",
    "            spanProductRating=spanProductRating.text\n",
    "            spanProductRating_count=spanProductRating_count.text\n",
    "\n",
    "\n",
    "        ### Recommended Products\n",
    "        reco_prods=[]\n",
    "        for tmp in soupBody.find_all('a', {'class':'tile-link-overlay u-focusTile'}):\n",
    "            reco_prods.append(tmp['data-product-id'])\n",
    "\n",
    "        if len(reco_prods)==0:\n",
    "            reco_prods=[\"Not available\"]\n",
    "        else:\n",
    "            reco_prods=reco_prods\n",
    "        print(len(reco_prods))\n",
    "        WLMTData.append([codelist[i],h1ProductName.text, divProductDesc.text,url2,\n",
    "                            liProductBreadcrumb_parent.text,liProductBreadcrumb_active.text,\n",
    "                        spanProductPrice.text,spanProductRating,spanProductRating_count,reco_prods])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print (str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures2 = []\n",
    "WLMTData = [[\"Product_code\",\"Product_name\", \"Product_description\",\"Product_URL\",\n",
    "                 \"Breadcrumb_parent\",\"Breadcrumb_active\",\n",
    "                \"Product_price\", \"Rating_Value\",\"Rating_Count\",\"Recommended_Prods\"]]\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for number in range(len(codelist)):\n",
    "        futures2.append(\n",
    "            executor.submit(run_process2,number,codelist)\n",
    "        )\n",
    "wait(futures2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pg in range(len(url_sets)):\n",
    "    # number of pages per category\n",
    "    top_n= [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
    "    url_category=url_sets[pg]\n",
    "    print(\"Category:\",categories[pg])\n",
    "    final_results = []\n",
    "    for i_1 in range(len(top_n)):\n",
    "        print(\"Page number within category:\",i_1)\n",
    "        url_cat=url_category+\"?page=\"+top_n[i_1]\n",
    "        driver= webdriver.Chrome(executable_path='C:/Drivers/chromedriver.exe')\n",
    "        driver.get(url_cat)\n",
    "        body_cat = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "        driver.quit()\n",
    "        soupBody_cat = BeautifulSoup(body_cat)\n",
    "        \n",
    "        \n",
    "        for tmp in soupBody_cat.find_all('div', {'class':'search-result-gridview-item-wrapper'}):\n",
    "\n",
    "            final_results.append(tmp['data-id'])\n",
    "    codelist=final_results\n",
    "    print(\"Total number of prods:\",len(codelist))\n",
    "    # base URL for product page\n",
    "    url1= \"https://walmart.com/ip\"\n",
    "\n",
    "    # Data Headers\n",
    "    WLMTData = [[\"Product_code\",\"Product_name\", \"Product_description\",\"Product_URL\",\n",
    "                 \"Breadcrumb_parent\",\"Breadcrumb_active\",\n",
    "                \"Product_price\", \"Rating_Value\",\"Rating_Count\",\"Recommended_Prods\"]]\n",
    "    for i in range(len(codelist)):\n",
    "        #creating a list without the place taken in the first loop\n",
    "        print(i)\n",
    "        item_wlmt=codelist[i]\n",
    "        url2=url1+\"/\"+item_wlmt\n",
    "        #print(url2)\n",
    "        \n",
    "        try:\n",
    "            driver= webdriver.Chrome(executable_path='C:/Drivers/chromedriver.exe') # Chrome driver is being used.\n",
    "            print (\"Requesting URL: \" + url2)\n",
    "\n",
    "            driver.get(url2)   # URL requested in browser.\n",
    "            print (\"Webpage found ...\")\n",
    "            time.sleep(5)\n",
    "            # Find the document body and get its inner HTML for processing in BeautifulSoup parser.\n",
    "            body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "            print(\"Closing Chrome ...\") # No more usage needed.\n",
    "            driver.quit() \t\t\t\t# Browser Closed.\n",
    "\n",
    "            print(\"Getting data from DOM ...\")\n",
    "            soupBody = BeautifulSoup(body) # Parse the inner HTML using BeautifulSoup\n",
    "            #print(soupBody)\n",
    "\n",
    "            h1ProductName = soupBody.find(\"h1\", {\"class\": \"prod-ProductTitle prod-productTitle-buyBox font-bold\"})\n",
    "            divProductDesc = soupBody.find(\"div\", {\"class\": \"about-desc about-product-description xs-margin-top\"})\n",
    "            liProductBreadcrumb_parent = soupBody.find(\"li\", {\"data-automation-id\": \"breadcrumb-item-0\"})\n",
    "            liProductBreadcrumb_active = soupBody.find(\"li\", {\"class\": \"breadcrumb active\"})\n",
    "            spanProductPrice = soupBody.find(\"span\", {\"class\": \"price-group\"})\n",
    "            spanProductRating = soupBody.find(\"span\", {\"itemprop\": \"ratingValue\"})\n",
    "            spanProductRating_count = soupBody.find(\"span\", {\"class\": \"stars-reviews-count-node\"})\n",
    "            \n",
    "            ################# exceptions #########################\n",
    "            if divProductDesc is None:\n",
    "                divProductDesc=\"Not Available\"\n",
    "            else:\n",
    "                divProductDesc=divProductDesc\n",
    "                \n",
    "            if liProductBreadcrumb_parent is None:\n",
    "                liProductBreadcrumb_parent=\"Not Available\"\n",
    "            else:\n",
    "                liProductBreadcrumb_parent=liProductBreadcrumb_parent\n",
    "                \n",
    "            if liProductBreadcrumb_active is None:\n",
    "                liProductBreadcrumb_active=\"Not Available\"\n",
    "            else:\n",
    "                liProductBreadcrumb_active=liProductBreadcrumb_active\n",
    "                \n",
    "            if spanProductPrice is None:\n",
    "                spanProductPrice=\"NA\"\n",
    "            else:\n",
    "                spanProductPrice=spanProductPrice\n",
    "\n",
    "            if spanProductRating is None or spanProductRating_count is None:\n",
    "                spanProductRating=0.0\n",
    "                spanProductRating_count=\"0 ratings\"\n",
    "            #print(spanProductBreadcrumb_active.text)\n",
    "            else:\n",
    "                spanProductRating=spanProductRating.text\n",
    "                spanProductRating_count=spanProductRating_count.text\n",
    "\n",
    "\n",
    "            ### Recommended Products\n",
    "            reco_prods=[]\n",
    "            for tmp in soupBody.find_all('a', {'class':'tile-link-overlay u-focusTile'}):\n",
    "                reco_prods.append(tmp['data-product-id'])\n",
    "\n",
    "            if len(reco_prods)==0:\n",
    "                reco_prods=[\"Not available\"]\n",
    "            else:\n",
    "                reco_prods=reco_prods\n",
    "            print(len(reco_prods))\n",
    "            WLMTData.append([codelist[i],h1ProductName.text, divProductDesc.text,url2,\n",
    "                            liProductBreadcrumb_parent.text,liProductBreadcrumb_active.text,\n",
    "                            spanProductPrice.text,spanProductRating,spanProductRating_count,reco_prods])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print (str(e))\n",
    "\n",
    "#WLMTData        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(WLMTData)\n",
    "df.columns = df.iloc[0]\n",
    "df=df.drop(df.index[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output File for FlightsData. This file will have the data in comma separated form.\n",
    "df.to_csv('out_laptops.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}